concat_channels_dim: 700
dmel_groups: 10
codec_ckpt_dir: /home/wzy/projects/dmel_codec/dmel_codec/ckpt/dmel_codec

data:
  stage: fit
  train_cuts_path: /home/wzy/projects/dmel_codec/train_cuts_windows-3_min_duration-3.0_max_duration-None.jsonl.gz
  val_cuts_path: /home/wzy/projects/dmel_codec/val_cuts_sample-128.jsonl.gz

  train_max_durations: 210.0 # dynamic batch size, seconds
  train_num_workers: 40
  val_max_durations: 4 # dynamic batch size, seconds
  val_num_workers: 2

  world_size: 2 # same with GPU number

model:
  accumulate_grad: 2 # gradient accumulation steps

  encoder:
    input_channels: 10
    residual_channels: 70

  vocoder:
    ckpt_path: /home/wzy/projects/bigvgan_v2_24khz_100band_256x/bigvgan_generator.pt
    h_path: /home/wzy/projects/bigvgan_v2_24khz_100band_256x/config.json

  optimizer:
    lr: 1e-4

  lr_scheduler:
    lr_lambda:
      num_training_steps: 100000 # 100k
      final_lr_ratio: 0.1

callbacks:
  model_checkpoint:
    dirpath: ${codec_ckpt_dir}
    filename: '{epoch:03d}-{step:06d}_20hz'

tensorboard_logger:
  _target_: lightning.pytorch.loggers.TensorBoardLogger
  save_dir: /home/wzy/projects/dmel_codec/tb_logs
  name: dmel_codec_20hz
  log_graph: true

trainer:
  accelerator: gpu
  precision: 32
  devices: [0, 1]
  max_steps: 10000000
  val_check_interval: 4000
